# -*- coding: utf-8 -*-
"""a4_t2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1do5lM1QszhbMfuJLoOipOSlUiO3CB7K7

## Task 2
"""

import os
import torch
import random
import torchvision
import imageio as io
import torch.nn as nn
import torch.optim as optim
from torchvision import utils
import torch.nn.functional as F
import torchvision.datasets as datasets
from torch.utils.data import DataLoader, Dataset
import torchvision.transforms as transforms
from torch.utils.tensorboard import SummaryWriter
import matplotlib.pyplot as plt
import torchvision.utils as vutils

device = 'cuda' if torch.cuda.is_available() else 'cpu'

classes =  ["airplane", "automobile", "bird", "cat", "deer", "dog", "frog", "horse", "ship", "truck"]

def loadDataset(path):
    print('Loading Dataset...')
    train, test = [], []
    for i in range(10):
        for filename in os.listdir(path+"/train/"+classes[i]):
            train.append((path+"/train/"+classes[i]+"/"+filename, i))
    for i in range(10):
        for filename in os.listdir(path+"/test/"+classes[i]):
            test.append((path+"/test/"+classes[i]+"/"+filename, i))
    print('Dataset loaded...')
    return train, test

class Real(Dataset):
    def __init__(self, data, transform=None):
        self.data = data
        self.transform = transform
    
    def __getitem__(self, index):
        image = io.imread(self.data[index][0])
        label = self.data[index][1]
        if self.transform:
            image = self.transform(image)
        
        return image, label
    
    def __len__(self):
        return len(self.data)

class DIS(nn.Module):
    def __init__(self):
        super(DIS, self).__init__()
        self.conv0 = nn.Conv2d(in_channels=3, out_channels = 32, kernel_size=3, stride=2, padding=1) #16x16x32
        self.bn0 = nn.BatchNorm2d(num_features=32)
        self.conv1 = nn.Conv2d(in_channels=32, out_channels = 64, kernel_size=3, stride=2, padding=1) #8x8x64
        self.bn1 = nn.BatchNorm2d(num_features=64)
        self.conv2 = nn.Conv2d(in_channels=64, out_channels = 128, kernel_size=3, stride=2, padding=1) #4x4x128
        self.bn2 = nn.BatchNorm2d(num_features=128)
        self.conv3 = nn.Conv2d(in_channels=128, out_channels = 1, kernel_size=3, stride=2) #1x1x1

        self.fc0 = nn.Linear(4*4*128, 128)
        self.dp = nn.Dropout(0.2)
        self.fc1 = nn.Linear(128, 10)
    def forward(self, x):
        out = F.relu(self.bn0(self.conv0(x)))
        out = F.relu(self.bn1(self.conv1(out)))
        out = F.relu(self.bn2(self.conv2(out)))
        classifier_input = out.view(-1, 4*4*128)
        real_fake_output = F.sigmoid(self.conv3(out))
        classifier_output = self.dp(F.relu(self.fc0(classifier_input)))
        classifier_output = self.fc1(classifier_output)
        return real_fake_output, classifier_output

class GEN(nn.Module):
    def __init__(self):
        super(GEN, self).__init__()
        self.dconv0 = nn.ConvTranspose2d(in_channels=100, out_channels=128, kernel_size=4, stride=1)
        self.bn0 = nn.BatchNorm2d(num_features=128)
        self.dconv1 = nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=4, stride=2, padding=1)
        self.bn1 = nn.BatchNorm2d(num_features=64)
        self.dconv2 = nn.ConvTranspose2d(in_channels=64, out_channels=32, kernel_size=4, stride=2, padding=1)
        self.bn2 = nn.BatchNorm2d(num_features=32)
        self.dconv3 = nn.ConvTranspose2d(in_channels=32, out_channels=3, kernel_size=4, stride=2, padding=1)
    
    def forward(self, x):
        out = F.relu(self.bn0(self.dconv0(x)))
        out = F.relu(self.bn1(self.dconv1(out)))
        out = F.relu(self.bn2(self.dconv2(out)))
        out = self.dconv3(out)
        return out

def train(d, g, epochs, loss,c_loss, loader, d_optimizer, g_optimizer, fixed_noise,  save_images=True):
    print("training model...")
    print(f"device available is : {device}")
    generator_losses = []
    discriminator_losses = []
    for epoch in range(epochs):
        generator_loss = 0
        discriminator_loss = 0
        for real_images, class_labels in loader:
            real_images = real_images.to(device)
            class_labels = class_labels.to(device)
            batch_size = real_images.size(0)
            #training discriminator
            #real images
            d.zero_grad()
            labels = torch.ones(batch_size, 1, 1, 1, device=device) #label is one
            d_output_real, d_output_label = d(real_images)
            d_loss_real = loss(d_output_real.float(), labels.float())
            d_loss_classifier = c_loss(d_output_label, class_labels)

            d_total_loss = d_loss_real + d_loss_classifier
            d_total_loss.backward()
            

            #fake images
            labels = torch.zeros(batch_size, 1, 1, 1, device=device) #label is zero
            noise = torch.randn(batch_size, 100, 1, 1, device = device)
            noise = torch.tensor(noise, device = device)
            fake_images = g(noise)
            d_output_fake, d_output_label = d(fake_images.detach())
            d_loss_fake = loss(d_output_fake.float(), labels.float())
            d_loss_fake.backward()

            d_loss = d_loss_real + d_loss_fake #We didn't add the d_loss_classifer becuause for fake we don't have class
            discriminator_loss += d_loss.item()
            d_optimizer.step()
            
            #training generator
            g.zero_grad()
            labels = torch.ones(batch_size, 1, 1, 1, device=device) #label is one
            g_d_output_fake, g_d_output_label = d(fake_images)
            g_loss = loss(g_d_output_fake.float(), labels.float())
            g_loss.backward()
            g_optimizer.step()
            generator_loss += g_loss.item()
            # print(f"loss_d: {d_loss.item()}, loss_g: {g_loss.item()}")
        discriminator_losses.append(discriminator_loss/batch_size)
        generator_losses.append(generator_loss/batch_size)
        fake_images = g(fixed_noise)
        if save_images:
            vutils.save_image(fake_images.detach(),PATH_TO_SAVE_IMAGES+'fake_images_epoch_%02d.png' % (epoch),normalize=True)
        print(f"epoch: {epoch}, loss_d: {discriminator_losses[-1]}, loss_g: {generator_losses[-1]}")
    return discriminator_losses,generator_losses

def plot_train_result(losses, details):
    headings = ["Discriminator_loss","Generator_loss"]
    fig = plt.figure(figsize=(12,6))
    for i, loss in enumerate(losses):
        plt.subplot(1,2,1+i)
        plt.title(headings[i])
        plt.xlabel("Epochs")
        plt.ylabel("Loss")
        plt.plot(loss)
    fig.suptitle(details, fontsize=14, fontweight="bold")
    plt.show()

def save_model(net, path):
    print("saving model...")
    torch.save(net.state_dict(), path)

def load_model(net, path):
    print("loading model...")
    state_dict = torch.load(path, map_location='cpu')
    net.load_state_dict(state_dict)

GENERATOR_INPUT_CHANNELS = 100
LR = 0.01
BATCH_SIZE = 2048
EPOCHS = 4
LOSS_FN = nn.BCELoss()
LOSS_C = nn.CrossEntropyLoss()
PATH = "/content"
PATH_TO_LOAD_MODEL = '/content/'
PATH_TO_SAVE_MODEL = '/content/'
PATH_TO_SAVE_IMAGES = '/content/'

D_LOSSES = []
G_LOSSES = []

def main(train_net, save_net, save_images, plot_train_results):
    train_data, test_data = loadDataset(PATH)
    train_dataset = Real(train_data,  transform=transforms.ToTensor())
    test_dataset = Real(test_data, transform=transforms.ToTensor())
    train_loader = DataLoader(train_dataset, BATCH_SIZE, shuffle=True)
    test_loader = DataLoader(test_dataset, BATCH_SIZE, shuffle=True)

    g = GEN().to(device)
    d = DIS().to(device)
    D_OPTIM = optim.Adam(d.parameters(), lr=LR)
    G_OPTIM = optim.Adam(g.parameters(), lr=LR)
    fixed_noise = torch.randn(16, 100, 1, 1, device = device)
    if train_net:
      D_LOSSES, G_LOSSES = train(d,g, EPOCHS, LOSS_FN,LOSS_C, train_loader, D_OPTIM, G_OPTIM, fixed_noise, save_images)
    else:
      load_model(g, PATH_TO_LOAD_MODEL+"t2_g.pt")
      load_model(d, PATH_TO_LOAD_MODEL+"t2_d.pt")
    if save_net:
      save_model(g, PATH_TO_SAVE_MODEL+"t2_g.pt")
      save_model(d, PATH_TO_SAVE_MODEL+"t2_d.pt")
    details = f"Batch_size: {BATCH_SIZE}, Epochs: {EPOCHS}, LR: {LR}"
    if plot_train_results:
        plot_train_result([D_LOSSES, G_LOSSES], details )

main(True, True, True, True)

